{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "from pathlib import Path\n",
    "from omegaconf import OmegaConf, DictConfig\n",
    "from pipe import select\n",
    "\n",
    "import wandb\n",
    "from wandb.util import generate_id\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import random_split, TensorDataset\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"act\", type=str)\n",
    "    parser.add_argument(\"subj_id\", type=int)\n",
    "    parser.add_argument(\"data_config_path\", type=Path)\n",
    "    parser.add_argument(\"config_wandb_path\", type=Path)\n",
    "    parser.add_argument(\"output_dir\", type=Path)\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    wandb_config = OmegaConf.load(args.config_wandb_path)\n",
    "    # load config file\n",
    "    data_config: DictConfig = OmegaConf.load(args.data_config_path)\n",
    "\n",
    "    torch.manual_seed(data_config.seed)\n",
    "\n",
    "    run = wandb.init(\n",
    "        name=\"data-\" + generate_id(),\n",
    "        config=data_config,\n",
    "        tags=[\"normalized\", f\"subj{args.subj_id}\", args.act,\n",
    "              f\"len{data_config.data.max_len}\", \"act_code_split\"],\n",
    "        **dict(wandb_config)\n",
    "    )\n",
    "\n",
    "    dataset: TensorDataset = torch.load(args.output_dir / \"full_dataset.pkl\", weights_only=False)\n",
    "    # last trajectory goes to test, others - to train\n",
    "    traj_num_tensor = dataset.tensors[3]\n",
    "    max_traj_num = traj_num_tensor.max()\n",
    "    split_index = (traj_num_tensor == max_traj_num).int().argmax().item()\n",
    "    train_dataset = TensorDataset(*list(\n",
    "        dataset.tensors | select(lambda t: t[:split_index])\n",
    "    ))\n",
    "    test_dataset = TensorDataset(*list(\n",
    "        dataset.tensors | select(lambda t: t[split_index:])\n",
    "    ))\n",
    "    # save datasets\n",
    "    torch.save(train_dataset, args.output_dir / \"train.pkl\")\n",
    "    run.log_artifact(\n",
    "        args.output_dir / \"train.pkl\",\n",
    "        f\"subj_{args.subj_id}_{args.act}_train\",\n",
    "        type=\"dataset\"\n",
    "    )\n",
    "    torch.save(test_dataset, args.output_dir / \"test.pkl\")\n",
    "    run.log_artifact(\n",
    "        args.output_dir / \"test.pkl\",\n",
    "        f\"subj_{args.subj_id}_{args.act}_test\",\n",
    "        type=\"dataset\"\n",
    "    )\n",
    "\n",
    "    run.log({f\"train_datapoints_{args.act}\": train_dataset.tensors[0].numel()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "node-py3.13",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
